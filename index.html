<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <title>Sambarta Ray</title>
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href="./styles/main.css">
    </head>

    <body>
        <div id="container--main">

            <section id="wrapper--hero" class="section--page">
                <img id="profile-pic" src="./assets//images/Potrait_cropped_profile.jpg"/>
                <div>
                    <p id="bio">Machine Learning and Software Engineer at <a href="https://www.manus-robotics.com/" target="_blank">Manus Robotics</a></p>
                    <p id="email">üëâ sambarta1202@outlook.com</p>
            </section>

            <section class="section--page">

                <div id="socials--list">
                    <a href="https://www.linkedin.com/in/sambarta-ray/" target="_blank">Linkedin</a>
                    <a href="https://github.com/srayhit" target="_blank">Github</a>
                    <a href="https://www.instagram.com/sambartaray/" target="_blank">Instagram</a>
                    <a href="./assets/resume.pdf" target="_blank">Download Resume</a>
                </div>
            </section>

            <section class="section--page">
                <h2>Skills & Qualifications</h2>
                <ul id="qualifications--list">
                    <li>‚úîÔ∏è +5 Years experience with start-up, R&D, prototyping and product development.</li>
                    <li>‚úîÔ∏è +7 Years experience with software development, system design and AI/ML R&D.</li>
                    <li>‚úîÔ∏è Proven track record of developing hardware prototypes from concept. </li>
                    <li>‚úîÔ∏è Manus's Hemyo prototype was launched and showcased in Touch Taiwan 2025 - One of the largest tech expo of South-East Asia</li>
                    <li>‚úîÔ∏è Key contributor in securing multi-million dollar grants from National Science Foundation and other research institutions </li>
                    <li>‚úîÔ∏è Experienced in wearable robotics, software development, hardware simulation, prototyping and Embedded Systems for real-world contextual AI Applications</li>
                    <li> <a href="https://www.youtube.com/@manusrobotics5945">üëâ Project demo done at Manus Robotics</a></li>
                </ul>
            </section>  

            <section class="section--page">
                <h2>Tech stack</h2>

                <div id="wrapper--techstack__items">
                    <div class="card--techstack"><span>Python, C/C++, Java, MATLAB, SQL, JavaScript</span></div>
                    <div class="card--techstack"><span>TensorFlow, PyTorch, Keras, Scikit-learn, Feature Engineering, Transfer Learning</span></div>
                    <div class="card--techstack"><span>2D/3D Perception, ROS, Gazebo, PCL, TurtleBot, Arduino, Universal Robot Arm</span></div>
                    <div class="card--techstack"><span>Generative AI, Computer Vision, NLP, Signal Processing, Embedded Systems</span></div>
                </div>
            </section>

            <section id="work-history-wrapper" class="section--page">
                <h2>Work History</h2>

                <div class="line-break"></div>
                <div class="card--work-history">
                    <strong>üöß Machine Learning Engineer & Data Scientist | Manus Robotics, Somerville, MA</strong>
                    <p>Dec 2020 - Present</p>
                    <p>Primary software developer and machine learning engineer for a small-scale startup based out of MIT in Boston, MA. Led the development of multimodal muscle activity sensing technology for assistive robotics and commercial gesture control system. Our game-changing algorithm detects the hand-gestures from a wearable wrist-band with sensors like PPG, IMU and piezo-electric thin films.</p>
                    <ul>
                        <li>Key contributor to securing NSF SBIR Phase II award worth <b>$1M</b> to advance wearable gesture recognition technology to 30 million differently abled survivors of stroke, SCI and TBI around the globe.</li>
                        <li>Key contributor to securing <b>NSF TECP </b> grant worth $250K and finishing work for <b>NSF SBIR Phase I award</b> worth <b>$250K</b>.</li>
                        <li>Co-inventor of patent-pending gesture detection algorithm for real-time, always-on AI applications.Entitled: <b>Gesture Detection Based on Direction Policies</b></li>
                        <li>Achieved 94% accuracy of detecting 5 gestures with on-device learning and classification.</li>
                        <li>Presented research and prototypes at MIT Digital Technology & Strategy Conference, MIT R&D Conference, and MIT Startup Ecosystem Conference.</li>
                        <li>Collaborated with cross-functional teams including hardware engineers, data scientists, and product managers to deliver functional prototypes.</li>
                    </ul>
                </div>
                <div class="line-break"></div>
                <div class="card--work-history">
                    <strong>üöß Software Engineer | Arizona State University, Tempe, AZ</strong>
                    <p>Jan 2019 - Nov 2020</p>
                    <p>Senior researcher in ASU‚Äôs START Lab under the supervision of Dr Claire Honeycutt. Responsible for conducting research on Fall prevention mechanisms using Smart Orthotics for people with lower-limb disability due to stroke or other neuro-muscular conditions.</p>
                    <ul>
                        <li>Led a team of 15 people in analyzing, debugging, filtering EMG data from clinical experiments for grant review and journal publication. Presented work at the BRAIN Center annual IAB meeting.</li>
                        <li>Pivoted to android-based remote data collection to facilitate research continuity during the COVID19 lockdown. Generated a <b>$20K</b> grant even during the economic downturn due to the immediate impact of the remote app.</li>
                        <li>Collaborated with cross-functional teams including hardware engineers, data scientists, and product managers to deliver functional prototypes.</li>
                    </ul>
                </div>
                <div class="line-break"></div>
                <div class="card--work-history">
                    <strong>üöß Software Development Engineer  | Tata Consultancy Services, Chennai, India</strong>
                    <p>Sep 2016 - Jun 2018</p>
                    <p>Software developer in a large scale B2B project for a leading US Bank and responsible for developing and maintaining critical banking software packages.</p>
                    <ul>
                        <li>Reduced 65% of defect list and delivered change requests 3 months ahead of schedule saving <b>$700K</b> and winning Star Team Award from client-side.</li>
                        <li>Conducted corporate training of 20 associates in best coding practices, project management, business communication, agile delivery and got awarded the Star of Learners Group</li>
                    </ul>
                </div>

                <div class="line-break"></div>

                <div class="card--work-history">
                    <strong>üöß Embedded Systems Engineer | New Jersey Institute of Technology, Newark, NJ</strong>
                    <p>Jun 2015 - Aug 2015</p>
                    <p>Designed an autonomous obstacle course navigating robot using spiking neural networks, based on neuro-synaptic processing of an insect. Presented the work at the VLSID 2016 international conference of embedded systems.</p>
                    <ul>
                        <li>Designed prototype & pitched original idea for a SNN control micro-robot that can avoid obstacles</li>
                        <li>Presented idea at multiple conferences including NJIT symposium that included researchers from NSF and NASA. Final Paper presented at VLSID 2016 Internation Conference</li>
                    </ul>
                </div>
            </section>

            <section class="section--page">
                <h2>Projects & Accomplishments</h2>

                <div class="card--project">
                    <a href="https://drive.google.com/file/d/1muSo9QSBo4m8CsLVf3fFVsNBYk1gXOXw/view"><span>Click üëâ:</span> Design of Ankle Foot Orthosis for gait rehabilitation and fall prevention (Thesis)</a>
                    <ul>
                        <li>Engineered an ankle robotic orthosis using pneumatic actuators, ESP8266 Microcontroller, BNO055 IMU sensors, I2C multiplexers, and phase-based custom control algorithm. </li>
                        <li>Developed a custom DAQ System using MATLAB and designed a wearable IMU-based embedded system to detect trip events using scikit learn, logistics regression, and time series analysis.</li>
                        <li>Improved the Ground Reaction Force of up to 116% that can potentially help prevent falls in stroke survivors.</li>
                        <li>Paper published in IRATJ 2020.</li>
                    </ul>
                </div>

                <div class="card--project">
                    <a href="https://drive.google.com/file/d/1xNl0ragPrRVXzjRQYASynbAkGzUfCBww/view" ><span>Click üëâ:</span> Bridge Collision Detection System using perception-based robotics</a>
                    <ul>
                        <li>Developed autonomous driving features for trucks to avoid overhead bridge collision using a depth-sensing camera with 90% accuracy in detecting bridge heights. </li>
                        <li>Utilized Point Cloud Library (PCL) in ROS framework with RANSAC algorithm.</li>
                        <li>Developed optimized methods for estimation of camera parameters through physical testing using TurtleBot and Gazebo simulation.</li>
                    </ul>
                </div>

                <div class="card--project">
                    <a href="https://drive.google.com/file/d/1JZ1S493xllS8601bJK99p56oGM8tg9u3/view" ><span>Click üëâ:</span> Text-to-Image Synthesis using Generative Adversarial Networks</a>
                    <ul>
                        <li>Employed a Deep Learning-based GAN for synthesizing images from descriptive text sentences using CNN, ReLU, residual networks, Adam optimizer, and sigmoid activation.</li>
                        <li>Achieved 70% reduction in discriminator loss using both TensorFlow and PyTorch platforms.</li>
                    </ul>
                </div>

                <div class="card--project">
                    <a href="https://drive.google.com/file/d/1A4aYFbF3sa1iorjKfKSve9BNpFZqZovl/view"><span>Click üëâ:</span> Chatbot using Facebook‚Äôs Wit.ai app</a>
                    <ul>
                        <li>Developed a chatbot using Facebook‚Äôs messenger, developer‚Äôs platform, and wit.ai app.</li>
                        <li>NLP based chatbot for detecting human emotion and suggesting activities based on detected emotions.</li>
                        <li>Developed the app using Python, Flask, and PyMessenger and hosted it on the cloud using Heroku.</li>
                        <li>Facebook AI hackathon 2020.</li>
                    </ul>
                </div>

                <div class="card--project">
                    <a href="https://drive.google.com/file/d/1G9TB6xQ0zL6cdhKK0L_gsO4WEoP9s7iq/view"><span>Click üëâ:</span> Security and Surveillance using Computer Vision</a>
                    <ul>
                        <li>Developed a Computer Vision system for detecting facial occlusion and anomalous situations for security inside ATM kiosks with an accuracy of 75% in variable lighting conditions using Matlab.</li>
                        <li>Available on IEEE Xplore digital library with multiple citations.</li>
                    </ul>
                </div>

            </section>
            <section class="section--page">
                <h2>Publication</h2>

                <div class="card--publication">
                    <ul>
                        <li><a href="https://medcraveonline.com/IRATJ/IRATJ-06-00209.pdf"><b>IRATJ 2020: </b>Design of active ankle-foot orthotics for gait assistance and fall prevention.</a> </li>
                        <li><a href="https://ieeexplore.ieee.org/document/7443827"><b>INDICON 2015: </b>An intelligent and automated vision-based system for advanced security and surveillance in ATM.</a></li>
                        <li><b>VLSID 2016: </b>Motion control of insect-bot using Spiking Neural Networks.</li>
                        <li><b>ASU Thesis 2020: </b><a href="https://keep.lib.asu.edu/items/158636">A Study on the Analysis of Treadmill Perturbation Data for the Design of Active Ankle-Foot Orthosis to Prevent Falls and Gait Rehabilitation.</a></li>
                    </ul>
                </div>
            </section>

            <section class="section--page">
                <h2>Certification</h2>

                <div class="card--certification">
                    <ul>
                        <li><a href="https://drive.google.com/file/d/1fyjvW1il8I5VXnx0e10eSzQZmF9DKr9r/view">TensorFlow Developer Professional Certification.</a> </li>
                        <li><a href="https://drive.google.com/file/d/1e5dnZTQPHJyTn_Kt9UWarJxC9aYsN-HR/view">Fundamentals of Deep Learning for Computer Vision.</a></li>
                        <li><a href="https://drive.google.com/file/d/1AKgVvYIkSKhu2H1M4mCYkN0eHqU249rI/view">Google Cloud Platform End to end Machine Learning with TensorFlow.</a></li>
                        <li>AWS AI/ML Bootcamp: End to end pipeline using BERT, TensorFlow, and SageMaker.</li>
                        <li><a href="https://drive.google.com/file/d/1eJbzVtvaZ8gCxdOA-8Xiv6387yJ6gDGd/view">Control of Mobile Robots from Georgia Tech.</a></li>
                    </ul>
                </div>
            </section>

            </div>



        </div>


    </body>

</html>